* Kubernetes Components
  * MASTER Components
    ETCD - ETCD data store stores information regarding nodes,pods, configs, roles, accounts and secrets.
         every information you see when you run kubectl get command that information from ETCD. it stores
         the information in key value format.
   
   kube-apiserver - when run kubectl command that kubectl utility reaches the kube-apiserver kubeapi server
         authenticates the request and validates and then retrieve the information from ETCD.
                    
   kube controller manager - manages various controllers in kubernetes, contineously monitors the status of the pods
        and takes the necessary actions to remediate the situation
                             
   Node controller - contineously monitors the status of the nodes, taking necessary actions to keep the application
        running
        
   Replication controller - contineously monitors the replicasets, desired number of replica sets are running or not,
      if a pod dies it creates another one.
      
  Kube scheduler - it should decide which pod should go to which node
  
* Node Components
  kubelet - An agent that runs on each node in the cluster. It makes sure that containers are running in a Pod.
  
  kube-proxy - kube-proxy is a network proxy that runs on each node in your cluster, kube-proxy maintains network rules on nodes. 
    These network rules allow network communication to your Pods
   
  Container runtime - The container runtime is the software that is responsible for running containers.
         
<== POD ==> 
   A Pod (as in a pod of whales or pea pod) is a group of one or more containers, 
   with shared storage and network resources, and a specification for how to run the containers.
   In terms of Docker concepts, a Pod is similar to a group of Docker containers with shared namespaces and shared filesystem volumes.
      
   YAML file containes:- 
   apiVersion - Which version of the Kubernetes API you're using to create this object
   kind - What kind of object you want to create
   metadata - Data that helps uniquely identify the object, including a name string, UID, and optional namespace
   spec - What state you desire for the object
   
   <== commands ==>
   - kubectl get pods (to check how many pods exist on the system)
   - kubectl run nginx --image=nginx ( to create the pod from nginx image)
   - kubectl describe pod nginx ( to describe and to know more about the pod )
   - kubectl delete pod webapp ( to delete the pod )
   - kubectl run redis --image=redis123 --dry-run=client -o yaml > redis-definition.yaml
   - kubectl label pods redis tier='db'
   - kubectl run custom-nginx --image=nginx --port=8080 (to expose the container port)
   
  <== YAML file to create the pod ==>
  
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  lables:
    app: myapp
    type: front-end
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80
   
<== Replicaset ==> 
 - A ReplicaSet ensures that a specified number of pod replicas are running at any given time. 
 - However, a Deployment is a higher-level concept that manages ReplicaSets and provides declarative updates to Pods along with a lot of other useful features.
 - Therefore, we recommend using Deployments instead of directly using ReplicaSets, unless you require custom update orchestration or don't require updates at all.
 
 <== commands ==>
 - kubectl replace -f replicaset-definition.yaml
 - kubectl scale --replicas=6 -f replicaset-definition.yaml
 - kubectl scale --replicas=6 replicaset myapp-replicaset
 - 
 <== YAML file to create the replicaset ==>
  
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: replicaset-1
spec:
  replicas: 2
  selector:
    matchLabels:
      tier: frontend
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: nginx
        image: nginx
         
<== deployment ==>
 - You can define Deployments to create new ReplicaSets, or to remove existing Deployments and adopt all their resources with new Deployments.
 - A new ReplicaSet is created and the Deployment manages moving the Pods from the old ReplicaSet to the new one at a controlled rate.
 - Each new ReplicaSet updates the revision of the Deployment.
         
<== commands ==>
  - kubectl create deployment --image=nginx nginx
  - kubectl create deployment --image=nginx nginx --dry-run=client -o yaml
  - kubectl create deployment --image=nginx nginx --dry-run=client -o yaml > nginx-deployment.yaml
  - kubectl create -f nginx-deployment.yaml
  - kubectl expose deployment nginx --port 80
  - kubectl edit deployment nginx
  - kubectl create deployment --image=nginx nginx --replicas=4 --dry-run=client -o yaml > nginx-deployment.yaml
  - kubectl set image deployment/nginx-deployment nginx=nginx:1.16.1 ( update the nginx Pods to use the nginx:1.16.1 image instead of the nginx:1.14.2 image)
  - kubectl rollout status deployment/nginx-deployment ( To see the rollout status )
  - kubectl rollout undo deployment/nginx-deployment ( undo the current rollout and rollback to the previous revision )
  Note:- you can pause rollouts for that Deployment before you trigger one or more updates
  - kubectl rollout pause deployment/nginx-deployment
  - kubectl rollout history deployment/nginx-deployment
  - kubectl rollout resume deployment/nginx-deployment
  
* Progressing Deployment
 - The Deployment creates a new ReplicaSet
 - The Deployment is scaling up its newest ReplicaSet
 - The Deployment is scaling down its older ReplicaSet
 - New Pods become ready or available
  
<== YAML file to create deployment ==>

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: deployment-1
spec:
  replicas: 2
  selector:
    matchLabels:
      name: busybox-pod
  template:
    metadata:
      labels:
        name: busybox-pod
    spec:
      containers:
      - name: busybox-container
        image: busybox888
        command:
        - sh
        - "-c"
        - echo Hello Kubernetes! && sleep 3600
  
<== Services ==?
 - service enables to connect from one group of pods to another group of pods
 - An abstract way to expose an application running on a set of Pods as a network service.
 - Kubernetes gives Pods their own IP addresses and a single DNS name for a set of Pods, and can load-balance across them.
 
 * NodePort
   - Exposes the Service on each Node's IP at a static port (the NodePort).
   - A ClusterIP Service, to which the NodePort Service routes, is automatically created.
   - You'll be able to contact the NodePort Service, from outside the cluster, by requesting <NodeIP>:<NodePort>.
   - If you set the type field to NodePort, the Kubernetes control plane allocates a port from a range (default: 30000-32767).
   
 * ClusterIP
   - Exposes the Service on a cluster-internal IP. Choosing this value makes the Service only reachable from within the cluster.
   
 * External IPs
   - If there are external IPs that route to one or more cluster nodes, Kubernetes Services can be exposed on those externalIPs.
   - Traffic that ingresses into the cluster with the external IP (as destination IP), on the Service port, will be routed to one of the Service endpoints. 
   - 
   
 * LoadBalancer
   -  Exposes the Service externally using a cloud provider's load balancer. 
   -  NodePort and ClusterIP Services, to which the external load balancer routes, are automatically created.
   
<== YAML file for the NodePort ==>
---
apiVersion: v1
kind: Service
metadata:
  name:webapp-service
spec:
  type: NodePort
  ports:
    - targetPort: 8080
      port: 8080
      nodePort: 30080
  selector:
    name: simple-webapp
    
<== YAML file for ClusterIP ==>
apiVersion: v1
kind: Service
metadata:
  name: redis-service
spec:
  type: ClusterIP #optional for ClusterIP
  selector:
    app: redis
  ports:
    - protocol: TCP
      port: 6379
      targetPort: 6379
      
<== YAML file for LoadBalancer ==>
---
apiVersion: v1
kind: Service
metadata:
 name: darwin-service
spec:
 selector:
  app: example
 ports:
  - port: 8765
    targetPort: 9376
    type: loadBalancer
    
<== YAML file for External IPs ==>
apiVersion: v1
kind: Service
metadata:
  name: my-service
spec:
  selector:
    app: MyApp
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 9376
  externalIPs:
    - 80.11.12.10
    
 <== commands ==>
 - kubectl create service nodeport <myservicename>
 - kubectl create service clusterip my-svc --clusterip="None" -o yaml --dry-run=client > srv.yaml
 - kubectl create --edit -f srv.yaml
 - kubectl expose pod redis --port=6379 --name redis-service --dry-run=client -o yaml (Create a Service named redis-service of type 
 ClusterIP to expose pod redis on port 6379)
 - kubectl create service clusterip redis --tcp=6379:6379 --dry-run=client -o yaml (This will not use the pods labels as selectors, instead it will assume selectors as app=redis. 
 You cannot pass in selectors as an option. 
 So it does not work very well if your pod has a different label set. 
 So generate the file and modify the selectors before creating the service)
 - kubectl expose pod nginx --type=NodePort --port=80 --name=nginx-service --dry-run-client -o yaml
 (This will automatically use the pod's labels as selectors, but you cannot specify the node port.
 ou have to generate a definition file and then add the node port in manually before creating the service with the pod.)
 - kubectl create service nodeport nginx --tcp=80:80 --node-port=30080 --dry-run=client -o yaml
 
* Namespaces
  - Namespaces are a way to divide cluster resources between multiple users
  - In Kubernetes, namespaces provides a mechanism for isolating groups of resources within a single cluster.
  - Names of resources need to be unique within a namespace, but not across namespaces. 
  
  <== commands ==>
  - kubectl get pods --namespace=dev
  - kubectl get pods --all-namespaces
  - kubectl config set-context $(kubectl config current-context) --namespace=dev ( to move the namespace permanently, whatever we create the pods that would be
                                                                                  created on dev namespace)
  - kubectl get ns
  - kubectl run redis --image=redis -n finance 
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
         
